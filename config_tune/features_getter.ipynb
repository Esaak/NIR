{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=152) # old number=42, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"output_19_01_2025/\"\n",
    "folder_path_outputs = '/app/nse/outputs/' + data_folder\n",
    "file_path_results = '/app/nse/results/' + data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        # Skip the first three lines\n",
    "        for _ in range(3):\n",
    "            next(file)\n",
    "        \n",
    "        # Read the rest of the file\n",
    "        data = np.loadtxt(file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_paths(folder_path, folder_pattern):\n",
    "    folder_list = [folder_path + f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f)) and re.search(folder_pattern, f)]\n",
    "    folder_list.sort(key=os.path.getctime)\n",
    "    return folder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    match = re.search(r'C\\[(\\d+)\\]-avg-\\.plt', filename)\n",
    "    return int(match.group(1)) if match else float('inf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_filenames(filenames):\n",
    "    return sorted(filenames, key=extract_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(file_path, file_pattern):\n",
    "    file_list = [f for f in os.listdir(file_path) if os.path.isfile(os.path.join(file_path, f)) and re.search(file_pattern, f)]\n",
    "    file_list = sort_filenames(file_list)\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_to_file(file_path, line_number, text_to_add):\n",
    "    # Read the contents of the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Insert the new text at the specified line number\n",
    "    lines.insert(line_number - 1, text_to_add + '\\n')\n",
    "\n",
    "    # Write the modified contents back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_lines(file_path, lines_to_change, changed_lines):\n",
    "    # Read the contents of the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    i = 0\n",
    "    for idx, line in enumerate(lines):\n",
    "        if re.search(lines_to_change[i], line):\n",
    "            lines[idx] = changed_lines[i]\n",
    "            i+=1\n",
    "            if i == len(changed_lines):\n",
    "                break\n",
    "    if len(changed_lines) != i:\n",
    "        print(len(changed_lines) - i, \"lines not changed\")\n",
    "     \n",
    "    # Write the modified contents back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_folder_names = get_folder_paths(folder_path_outputs, \"output*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in outputs_folder_names:\n",
    "    config_path = folder + \"/config.txt\"\n",
    "    data_config = read_data(config_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text added successfully to /app/nse/outputs/config-plume-ex_999.txt at line 346.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx in range(n_files):\n",
    "\t\n",
    "\tfile_path = shutil.copyfile(file_path_initial, file_path_output + \"config-plume-ex_\" + str(idx) + \".txt\")\n",
    "\t\n",
    "\tu = rng.uniform(u_min, u_max)\n",
    "\tvalue = rng.uniform(value_min, value_max)\n",
    "\tz0_m = rng.uniform(z0_min, z0_max)\n",
    "\tT0 = rng.uniform(T0_min, T0_max)\n",
    "\tgradz = rng.uniform(gradz_min, gradz_max)\n",
    "\n",
    "\tlines_changed = [\n",
    "\t\tf'\tU = {u}; V = 0.0;\t\t\t# [m/s] \\n',\n",
    "\t\tf'\t\tvalue = {value};\t# sensible heat flux [K*m/s]\\n',\n",
    "\t\tf'\tz0_m = {z0_m};\t\t# aerodynamic roughness [m]\\n',\n",
    "\t\tf'\t\tsurface_value = {T0};\t# initial boundary layer temperature [K]\\n',\n",
    "\t\tf'\t\tgrad_z = {gradz};\t\t# temperature gradient above boundary layer [K/m]\\n',\n",
    "\t\tf'\tnum = {N};\t# number of tracers, skipped if not defined'\n",
    "\t]\n",
    "\tfor i in range(N, 0, -1):\n",
    "\t\tp = rng.uniform(p_min, p_max)\n",
    "\t\ty = rng.uniform(y_min, y_max)\n",
    "\t\tz = rng.triangular(z_min, z_mode, z_max)\n",
    "\t\t\n",
    "\t\ty_list.append(y)\n",
    "\t\tz_list.append(z)\n",
    "\t\tu_list.append(u)\n",
    "\t\tvalue_list.append(value)\n",
    "\t\tz0_list.append(z0_m)\n",
    "\t\tT0_list.append(T0)\n",
    "\t\tgradz_list.append(gradz)\n",
    "\t\tp_list.append(p)\n",
    "\n",
    "\t\t# Define the text to add\n",
    "\t\ttext_to_add = f\"\"\"\n",
    "\ttracer_{i} {{ \n",
    "\t\tdiffusivity = phys.xi;\n",
    "\n",
    "\t\tsurface {{ \n",
    "\t\t\tflux = 0.0;\n",
    "\t\t}}\n",
    "\n",
    "\t\t# --- point emission source [optional]\n",
    "\t\tpoint_emission {{\n",
    "\t\t\ttype = \"gaussian\";\t\t# \"gaussian\" || \"box\"\n",
    "\n",
    "\t\t\t# --- source intensity [ppb * m^3 / s]\n",
    "\t\t\tvalue = {p} * (2.0 / 3.14) * (1.0 / 2.46) * 1000.0 * 1000.0 * 100.0;\n",
    "\n",
    "\t\t\t# --- active in [begin, end], [time.begin, time.end] if not defined\n",
    "\t\t\tbegin = 0.5 * 3600.0;\t# [s]\n",
    "\n",
    "\t\t\txpos = domain.x + 0.25 * domain.length;\t\t# [m]\n",
    "\t\t\typos = domain.y + {y};\t\t# [m]\n",
    "\t\t\tzpos = {z};\t\t# [m]\n",
    "\t\t\t\n",
    "\t\t\tsx = 50.0;\t\t# [m]\n",
    "\t\t\tsy = 50.0;\t\t# [m]\n",
    "\t\t\tsz = 25.0;\t\t# [m]\n",
    "\n",
    "\t\t\t# --- OR set 'box'\n",
    "\t\t\t# type = \"box\";\n",
    "\t\t\t\n",
    "\t\t\t# xmin = 450.0; xmax = 550.0;\t# [m]\n",
    "\t\t\t# ymin = 450.0; ymax = 550.0;\t# [m]\n",
    "\t\t\t# zmin = 50.0; zmax = 250.0;\t# [m]\n",
    "\t\t}}\n",
    "\n",
    "\t\t# --- boundary conditions [optional]\n",
    "\t\tboundary_conditions\n",
    "\t\t{{\n",
    "\t\t\t# --- default: -xy periodic & neumann (= 0) at top and bottom\n",
    "\t\t\twest {{ type = \"inout\"; rhs = 0.0; }}\n",
    "\t\t\teast {{ type = \"inout\"; rhs = 0.0; }}\n",
    "\t\t\tsouth {{ type = \"inout\"; rhs = 0.0; }}\n",
    "\t\t\tnorth {{ type = \"inout\"; rhs = 0.0; }}\n",
    "\t\t}}\n",
    "\n",
    "\t\t# --- sedimentation & deposition [optional, default = false]\n",
    "\t\t# \t--- require density & diameter setup\n",
    "\t\t# is_sedimentation = false;\n",
    "\t\t# is_dry_deposition = false;\n",
    "\t\t# is_wet_deposition = false;\n",
    "\t\t# density = 10.0 * 1000.0;\t# [kg / m^3]\n",
    "\t\t# diameter = 10.0 * 0.000001;\t# [m]\n",
    "\t\t\n",
    "\t\t# --- min limit [optional, default = none]\n",
    "\t\t# min_value = 0.0;\n",
    "\t}}\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\t# Add the text to initial line\n",
    "\t\tadd_text_to_file(file_path, initial_line, text_to_add)\n",
    "\tchange_lines(file_path, lines_to_change, lines_changed)\n",
    "print(f\"Text added successfully to {file_path} at line 346.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pd = pd.DataFrame({\"y\": y_list,\n",
    "                            \"z\": z_list,\n",
    "                            \"u\": u_list,\n",
    "                            \"power\":p_list,\n",
    "                            \"roughness\": z0_list,\n",
    "                            \"T\": T0_list,\n",
    "                            \"sensible_heat_flux\":value_list,\n",
    "                            \"T_grad\":gradz_list})\n",
    "features_pd.to_csv(\"features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LES Configuration Parser and Data Analyzer\n",
    "----------------------------------------\n",
    "A robust tool for parsing and analyzing LES configuration files with a focus on tracer data.\n",
    "\n",
    "Author: Claude\n",
    "Version: 1.0.0\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class TracerData:\n",
    "    \"\"\"Data class for storing tracer-specific information.\"\"\"\n",
    "    index: int\n",
    "    y_pos: float\n",
    "    z_pos: float\n",
    "    value: float\n",
    "\n",
    "@dataclass\n",
    "class ConfigData:\n",
    "    \"\"\"Data class for storing configuration parameters.\"\"\"\n",
    "    U: float\n",
    "    z0_m: float\n",
    "    surface_value: float\n",
    "    grad_z: float\n",
    "    tracers: List[TracerData]\n",
    "\n",
    "class ConfigParser:\n",
    "    \"\"\"Parser for LES configuration files.\"\"\"\n",
    "    \n",
    "    def __init__(self, config_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the parser with the path to the configuration file.\n",
    "        \n",
    "        Args:\n",
    "            config_path (str): Path to the configuration file\n",
    "        \"\"\"\n",
    "        self.config_path = Path(config_path)\n",
    "        self.config_text = None\n",
    "        self.config_data = None\n",
    "\n",
    "    def read_config(self) -> None:\n",
    "        \"\"\"Read and store the configuration file content.\"\"\"\n",
    "        try:\n",
    "            with open(self.config_path, 'r') as f:\n",
    "                self.config_text = f.read()\n",
    "            logger.info(f\"Successfully read configuration file: {self.config_path}\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Configuration file not found: {self.config_path}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading configuration file: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _extract_float_value(self, pattern: str) -> float:\n",
    "        \"\"\"\n",
    "        Extract float value from config text using regex pattern.\n",
    "        \n",
    "        Args:\n",
    "            pattern (str): Regex pattern to match\n",
    "            \n",
    "        Returns:\n",
    "            float: Extracted value\n",
    "        \"\"\"\n",
    "        match = re.search(pattern, self.config_text)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not find value matching pattern: {pattern}\")\n",
    "        return float(match.group(1))\n",
    "\n",
    "    def _parse_tracers(self) -> List[TracerData]:\n",
    "        \"\"\"\n",
    "        Parse tracer information from config text.\n",
    "        \n",
    "        Returns:\n",
    "            List[TracerData]: List of tracer data objects\n",
    "        \"\"\"\n",
    "        tracers = []\n",
    "        tracer_sections = re.finditer(\n",
    "            r'tracer_(\\d+)\\s*{[^}]*point_emission\\s*{([^}]*)}', \n",
    "            self.config_text\n",
    "        )\n",
    "        \n",
    "        for section in tracer_sections:\n",
    "            index = int(section.group(1))\n",
    "            tracer_text = section.group(2)\n",
    "            \n",
    "            try:\n",
    "                value = float(re.search(r'value\\s*=\\s*([0-9.]+)', tracer_text).group(1))\n",
    "                y_pos = float(re.search(r'ypos\\s*=\\s*[^+]*\\+\\s*([0-9.]+)', tracer_text).group(1))\n",
    "                z_pos = float(re.search(r'zpos\\s*=\\s*([0-9.]+)', tracer_text).group(1))\n",
    "                \n",
    "                tracers.append(TracerData(index, y_pos, z_pos, value))\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error parsing tracer {index}: {e}\")\n",
    "                raise\n",
    "                \n",
    "        return sorted(tracers, key=lambda x: x.index)\n",
    "\n",
    "    def parse(self) -> ConfigData:\n",
    "        \"\"\"\n",
    "        Parse the configuration file and extract relevant data.\n",
    "        \n",
    "        Returns:\n",
    "            ConfigData: Parsed configuration data\n",
    "        \"\"\"\n",
    "        if not self.config_text:\n",
    "            self.read_config()\n",
    "\n",
    "        try:\n",
    "            # Extract main configuration values\n",
    "            U = self._extract_float_value(r'U\\s*=\\s*([0-9.]+)')\n",
    "            z0_m = self._extract_float_value(r'z0_m\\s*=\\s*([0-9.]+)')\n",
    "            surface_value = self._extract_float_value(r'surface_value\\s*=\\s*([0-9.]+)')\n",
    "            grad_z = self._extract_float_value(r'grad_z\\s*=\\s*([0-9.]+)')\n",
    "            \n",
    "            # Parse tracer data\n",
    "            tracers = self._parse_tracers()\n",
    "            \n",
    "            self.config_data = ConfigData(U, z0_m, surface_value, grad_z, tracers)\n",
    "            logger.info(\"Successfully parsed configuration data\")\n",
    "            \n",
    "            return self.config_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing configuration: {e}\")\n",
    "            raise\n",
    "\n",
    "class DataAnalyzer:\n",
    "    \"\"\"Analyzer for parsed configuration data.\"\"\"\n",
    "    \n",
    "    def __init__(self, config_data: ConfigData):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with parsed configuration data.\n",
    "        \n",
    "        Args:\n",
    "            config_data (ConfigData): Parsed configuration data\n",
    "        \"\"\"\n",
    "        self.config_data = config_data\n",
    "\n",
    "    def create_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a pandas DataFrame from the configuration data.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing all configuration data\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        \n",
    "        # Create rows for each tracer\n",
    "        for tracer in self.config_data.tracers:\n",
    "            row = {\n",
    "                'Tracer': tracer.index,\n",
    "                'y (m)': tracer.y_pos,\n",
    "                'z (m)': tracer.z_pos,\n",
    "                'p (value)': tracer.value,\n",
    "                'U (m/s)': self.config_data.U,\n",
    "                'z0_m (m)': self.config_data.z0_m,\n",
    "                'surface_value (K)': self.config_data.surface_value,\n",
    "                'grad_z (K/m)': self.config_data.grad_z\n",
    "            }\n",
    "            data.append(row)\n",
    "            \n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def save_to_csv(self, output_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Save the data to a CSV file.\n",
    "        \n",
    "        Args:\n",
    "            output_path (str): Path to save the CSV file\n",
    "        \"\"\"\n",
    "        df = self.create_dataframe()\n",
    "        df.to_csv(output_path, index=False)\n",
    "        logger.info(f\"Data saved to: {output_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate usage.\"\"\"\n",
    "    try:\n",
    "        # Initialize parser and parse config\n",
    "        parser = ConfigParser(\"config.txt\")\n",
    "        config_data = parser.parse()\n",
    "        \n",
    "        # Analyze and save data\n",
    "        analyzer = DataAnalyzer(config_data)\n",
    "        df = analyzer.create_dataframe()\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nParsed Configuration Data:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        # Save to CSV\n",
    "        analyzer.save_to_csv(\"les_config_analysis.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main execution: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
